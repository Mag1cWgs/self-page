## 最优化计算方法

- 开设于本科三年级上学期，作为全方向的选修课程。
- 使用课本：
    - [《最优化计算方法》 （刘浩洋, 户将, 李勇锋，文再文 高等教育出版社）](http://faculty.bicmr.pku.edu.cn/~wenzw/optbook/opt1-short.pdf)
        - [主页](/ProjectDocs/Mathematic/OptFile/最优化：建模、算法与理论_最优化计算方法.html)
        - [勘误](http://faculty.bicmr.pku.edu.cn/~wenzw/optbook/errata-short.pdf)
    - 详细版：[《最优化：建模、算法与理论》 （刘浩洋, 户将, 李勇锋，文再文 高等教育出版社）](http://faculty.bicmr.pku.edu.cn/~wenzw/optbook/opt1.pdf)
        - [刊误](http://faculty.bicmr.pku.edu.cn/~wenzw/optbook/errata.pdf)



---



## 考试相关

### 2024考试题型：
1. 填空题10分（每小题2分，5个小题）
2. 判断题10分（每小题2分，5个小题）
3. 计算题7到8个题（教材中例题，写过的练习题等）

### 最优化方法考察知识点
1. 第一章 最优化简介
    - 最优化问题的一般形式 `3页`
    - 全局和局部最优解 `16页`
    - 优化算法常用的收敛准则，收敛速度 `17—20页`

2. 第二章 基础知识
    - 梯度海瑟矩阵 `28-29页`
    - 凸集仿射集 `36页`
    - 半正定矩阵 `39页`
    - 凸函数： `42页`
        - 例题 2.5  `45页`
    - 次梯度次微分： `51页`
        - 例题 2.10 — 2.12 `55页`

3. 第三章 典型优化问题
    - 线性规划： `62-63页`
        - 习题 3.1 3.2 `78页`
    - 半定规划： `70—72页`
        - 习题 3.9 79页

4. 第四章最优性理论
    - 下降方向： `85页`
        - 线性化可行方向
        - LICQ
        - Slater条件等
    - 无约束可微问题的一阶必要条件，二阶最优性条件： `85—87页 `
        - 例题  `87页`
        - 习题 4.5 `115页`
    - 无约束不可微问题的最优性理论： `89——91页`
    - 对偶理论 例题 `96-100页`
        - 习题 4.7 `115页`
        - 习题 4.13 `116页 ` 
    - 一般约束优化问题的最优性理论：
        - 例题 `107页`
        - 习题 4.10 `116页`
    - 凸优化问题最优性理论：
        - 例题 `111页`
        - 习题 4.11(a)，4.6(b) `116页`

5. 第五章 无约束优化算法
    - 线搜索准则：
        - Armijo 准则 `121页`
        - Wolfe 准则 `123页`
    - 梯度法迭代计算 `128页`
        - 定理 5.2
        - 习题 5.2 `179页`
    - 步长：
        - 精确线性搜索；
        - BB 梯度法
        - BB 梯度法的两种迭代格式推理 `132页`
    - 牛顿类算法：
        - 牛顿方程 牛顿方向 经典牛顿法迭代格式 `141页`
    - 牛顿法的具体迭代计算：
        - 搜索方向 ：
            - 步长：1（即经典牛顿法）
            - 精确线性搜索
    - 拟牛顿类算法：
        - 割线方程 `148页`
        - 拟牛顿矩阵更新公式推理；
            - SR1公式 5.5.9 `150页`
            - BFGS公式推理5.5.12 `151页`

6. 第六章约束优化算法
    - 罚函数法：
        - 二次罚函数法
        - 对数罚函数法
    - 等式约束优化问题
        - 增广拉格朗日函数法 



---



## 第一章 最优化简介

### 考察内容
- 最优化问题的一般形式 `3页`
- 全局和局部最优解 `16页`
- 优化算法常用的收敛准则，收敛速度 `17—20页`

### 1.1 最优化问题概括

#### 1.1.1 最优化问题简介

最优化问题一般可以描述为:
$$
\min \space f(x), \tag{1.1.1} \\
s.t.\space x \in \chi
$$
其中:
- $x=(x_{1}, x_{2}, \cdots, x_{n})^{T}\in \mathbb{R}^{n}$ 是决策变量.
- $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ 是目标函数.
- $\chi \subseteq \mathbb{R}^{n}$ 是约束集合或可行域.
    - 可行域包含的点称为可行解或可行点.
- 记号 `s.t.` 是 “subject to”的缩写，专指约束条件.
- 当 $ \chi = R^{n} $ 时，问题（1.1.1）称为无约束优化问题.
- 集合 $\chi$ 通常可以由约束函数 $ c_{i}(x): \mathbb{R}^{n} \rightarrow \mathbb{R}, i=1, 2, \cdots, m+l $表达成如下形式：
    $$
    \begin{align}
    \chi = \{ x \in \mathbb{R}^{n} \mid  c_{i}(x) & \leq 0, i = 1, 2, \cdots, m, \notag \\
                c_{i}(x) & = 0, i = m+1, m+2, \cdots, m+l \}. \notag
    \end{align}
    $$
- 在所有满足上述约束条件的决策变量中，
    - 使目标函数 $f(x)$ 取最小值的变量 $x^*$ 称为优化问题（1.1.1）的最优解，即对于任意 $x \in X$ 都有 $f(x) \geq f(x^*)$.
    - 如果我们求解在约束集合 $X$ 上目标函数 $f(x)$ 的最大值，则问题（1.1.1）中的 “ $ \min $ ” 应相应地替换为 “ $ \max $ ” .
- 注意到在集合 $X$ 上，函数 $f$ 的最小（最大）值不一定存在，但是其下（上）确界 “ $\inf f(\sup f)$ ” 总是存在的.
    - 当目标函数的最小（最大）值不存在时，我们便关心其下（上）确界，即将问题（1.1.1）中的 “ $ \min (\max) $ ” 改为 “ $ \inf (\sup) $ ” .
- 为了叙述简便，问题（1.1.1）中的 $x$ 为 $\mathbb{R}^n$ 空间中的向量.
- 实际上，根据具体应用和需求，$x$ 还可以是矩阵、多维数组或张量等，本书介绍的很多理论和算法可以相应推广.


### 1.2 实例：稀疏优化（略）
### 1.3 实例：深度学习（略）
### 1.4 最优化的基本概念

#### 1.4.6  全局和局部最优解
在求解最优化问题之前，先介绍最小化问题(1.1.1)的**最优解**的定义．  

**定义1.1**（最优解）对于可行点 $\bar{x}$（即 $\bar{x} \in X$），定义如下概念：
1. 如果 $f(\bar{x}) \le f(x), \forall x \in X$，那么称 $\bar{x}$ 为问题（1.1.1）的 **全局极小解（点）**，有时也称为（全局）最优解或最小值点；
2. 如果存在 $\bar{x}$ 的一个 $\varepsilon$ 邻域 $N_{\varepsilon}(\bar{x})$ 使得 $f(\bar{x}) \le f(x), \forall x \in N_{\varepsilon}(\bar{x}) \cap X$，那么称 $\bar{x}$ 为问题（1.1.1）的 **局部极小解（点）**，有时也称为局部最优解；
3. 进一步地，如果有 $f(\bar{x}) < f(x), \forall x \in N_{\varepsilon}(\bar{x}) \cap X, x \neq \bar{x}$ 成立，则称 $\bar{x}$ 为问题（1.1.1）的 **严格局部极小解（点）**。
4. 如果一个点是局部极小解，但不是严格局部极小解，我们称之为**非严格局部极小解（点）**．

#### 1.4.7 优化算法

1. **迭代算法产生原因**
    - 在给定优化问题之后，我们要考虑如何求解．根据优化问题的不同形式，其求解的困难程度可能会有很大差别．
    - 对于一个优化问题，如果我们能用代数表达式给出其最优解，那么这个解称为**显式解**，对应的问题往往比较简单．
        - 例如二次函数在有界区间上的极小化问题，我们可以通过比较其在对称轴上和区间两个端点处的值得到最优解，这个解可以显式地写出．
    - 但实际问题往往是没有办法显式求解的，因此常采用**迭代算法**．

2. **迭代算法的基本思想**
    - 从一个初始点 $x^0$ 出发，按照某种给定的规则进行迭代，得到一个序列 $\{x^k\}$：
    - 如果迭代在有限步内终止，那么希望最后一个点就是优化问题的解.
    - 如果迭代点列是无穷集合，那么希望该序列的极限点（或者聚点）则为优化问题的解．

3. **收敛准则**
    - 为了使算法能在有限步内终止，我们一般会通过一些收敛准则来保证迭代停在问题的一定精度逼近解上．
    - 对于无约束优化问题，常用的收敛准则有
        $$
        \frac{f(x^{k}) - f^*}{\max \{ |f^*|, 1 \}} \leq \varepsilon_{1},
        \quad ||
        \nabla f(x^{k})|| \leq \varepsilon_{2} \tag{1.4.1}
        $$
        - 其中 $\varepsilon _{1}, \varepsilon _{2}$ 为给定的很小的正数.
        - $||\cdot ||$ 表示某种范数
            - 这里可以简单理解为 $l_{2}$ 范数：$\displaystyle||x||_{2}=(\sum _{i=1}^{n}x_{i}^{2})^{1/2}$，第二章将会给出范数的一般定义）.
        - $f^*$ 为函数 $f$ 的最小值（假设已知或者以某种方式估计得到）.
        - $\nabla f(x^{k})$ 表示函数 $f$ 在点 $x$ 处的梯度（光滑函数在局部最优点处梯度为零向量，第四章中会给出更多介绍）.
    - 对于约束优化问题，还需要考虑约束违反度。具体地，要求最后得到的点满足
        $$
        \begin{align}
          c_{i}(x^{k})  & \le \varepsilon _{3}, i=1, 2, \cdots, m, \notag   \\
        | c_{i}(x^{k})| & \le \varepsilon _{4}, i=m+1, m+2, \cdots, m+l, \notag
        \end{align}
        $$
        - 其中 $\varepsilon _{3}, \varepsilon _{4}$ 为很小的正数，用来刻画 $x^{k}$ 的可行性.

4. **解的最优性**
    - 除了约束违反度之外，我们也要考虑 $x^{k}$ 与最优解之间的距离.
        - 如 (1.4.1)式中给出的函数值与最优值的相对误差.
    - 由于一般情况下事先并不知道最优解，在**最优解唯一**的情形下一般使用某种**基准算法**来得到 $x^*$ 的一个估计，之后计算其与 $x^{k}$ 的距离以评价算法的性能.
    - 因为约束的存在，我们不能简单地用目标函数的梯度来判断最优性.
        - 实际中采用的**判别准则**是**点的最优性条件**的**违反度**（关于约束优化的最优性条件，会在第四章中给出）.

5. **停机准则**
    - 对于一个具体的算法，根据其设计的出发点，我们不一定能得到一个高精度的逼近解.
    - 此时，为了避免无用的计算开销，我们还需要一些停机准则来及时停止算法的进行。常用的停机准则有：
    $$
    \frac{||x^{k+1}-x^{k}||}{\max \{ ||x^{k}||, 1\}}\le \varepsilon _{5},
     \space 
    \frac{|f(x^{k+1})-f(x^{k})|}{\max \{ |f(x^{k})|, 1\}}\le \varepsilon _{6},
    $$
    - 这里的各个 $\varepsilon$ 一般互不相等.
    - 上面的准则分别表示相邻迭代点和其对应目标函数值的**相对误差很小**.
    - 在算法设计中，这两个条件往往只能反映迭代点列**接近收敛**，但**不能**代表收敛到优化问题的最优解.

6. **依点列收敛**
    1. 在算法设计中，一个重要的标准是算法产生的点列是否收敛到优化问题的解．
    2. 对于问题(1.1.1)，其可能有很多局部极小解和全局极小解，但所有全局极小解对应的目标函数值，即优化问题的最小值 $f^*$ 是一样的．
    3. 考虑**无约束**的情形，对于一个算法：  
        给定初始点$x^{0}$，记其迭代产生的点列为 $\{x^{k}\}$，如果 $\{x^{k}\}$ 在某种范数 $||\cdot ||$ 的意义下满足：
        $$
        \lim _{k\rightarrow \infty}||x^{k}-x^{*}||=0
        $$
        且收敛的点 $x^*$ 为一个局部（全局）极小解，那么我们称该点列收敛到局部（全局）极小解，
        相应的算法称为是**依点列收敛到局部（全局）极小解**的.
    4. 对于**带约束**的情形：  
        给定初始点 $x^{0}$，算法产生的点列 $\{x^{k}\}$ 不一定是可行的（即 $x^{k}\in \chi$ 未必对任意 $k$ 成立）.
        - 考虑到约束违反的情形，我们需要保证 $\{x^{k}\}$ 在收敛到 $x^*$ 的时候，其违反度是可接受的.
        - 除此要求之外，算法的收敛性的定义和无约束情形相同.
    
7. **依函数值收敛**
    1. 在算法的收敛分析中，初始迭代点 $x^{0}$ 的选取也尤为重要。
        - 比如一般的牛顿法，只有在初始点足够接近局部（全局）最优解时，才能收敛。
        - 但是这样的初始点的选取往往比较困难，此时我们更想要的是一个从任何初始点出发都能收敛的算法。
    2. 因此优化算法的研究包括如何设计全局化策略
        - 将已有的可能发散的优化算法修改得到一个新的全局收敛到局部（全局）最优解的算法。
        - 比如通过采用合适的全局化策略，我们可以修正一般的牛顿法使得修改后的算法是全局收敛到局部（全局）最优解的。
    3. 进一步地，如果从**任意**初始点 $x^{0}$ 出发，算法都是依点列收敛到局部（全局）极小解的，我们称该算法是**全局依点列收敛到局部（全局）极小解**的。
        - 相应地，如果记对应的函数值序列为 $\{f(x^{k})\}$，我们还可以定义算法的 **（全局）依函数值收敛到局部（全局）极小值** 的概念。
    4. 对于**凸优化**问题，因为其**任何局部最优解都为全局最优解**，算法的收敛性都是相对于其全局极小而言的。
        - 除了点列和函数值的收敛外，实际中常用的还有每个迭代点的最优性条件（如无约束优化问题中的梯度范数，约束优化问题中的最优性条件违反度等等）的收敛。 

8. **收敛速度**
    1. Q-收敛速度
        对于同一个优化问题，其求解算法可以有很多.  
        在设计和比较不同的算法时，另一个重要的指标是算法的渐进收敛速度.  
        我们以点列的 **Q-收敛速度** （*Q* 的含义为 “quotient” ）为例:  
        （函数值的 Q-收敛速度 可以类似地定义）   
        **设** $\{x^{k}\}$ 为算法产生的迭代点列且收敛于 $x^*$，
        - 若对充分大的 $k$ 有
        $$
        \frac{||x^{k+1}-x^{*}||}{||x^{k}-x^{*}||}\le a, \space a\in (0, 1),
        $$
        则称算法（点列）是 **Q-线性收敛的**；
        - 若满足
        $$
        \lim _{k\rightarrow \infty}\frac{||x^{k+1}-x^{*}||}{||x^{k}-x^{*}||}=0,
        $$
        称算法（点列）是 **Q-超线性收敛的**；
        - 若满足
        $$
        \lim _{k\rightarrow \infty}\frac{||x^{k+1}-x^{*}||}{||x^{k}-x^{*}||}=1,
        $$
        称算法（点列）是**Q-次线性收敛的**；
        - 若对充分大的 $k$ 满足
        $$
        \frac{||x^{k+1}-x^{*}||}{||x^{k}-x^{*}||^{2}}\le a, \space a>0,
        $$
        则称算法（点列）是 **Q-二次收敛** 的.
        - 类似地，也可定义更一般的 Q-r 次收敛 $(r>1)$.

    2. R-收敛速度
        除 Q-收敛速度外，另一常用概念是 **R-收敛速度**（R 的含义为“root”）.  
        以点列为例：  
        **设** $\{x^{k}\}$ 为算法产生的迭代点且收敛于 $x^*$，  
        - 若存在 Q-线性收敛 于 0 的非负序列 $t_{k}$ 并且对任意的 $k$ 有
        $$
        ||x^{k}-x^{*}||\le t_{k}
        $$
        成立，则称算法（点列）是 **R-线性收敛** 的.
        - 类似地，可定义 **R-超线性收敛** 和 **R-二次收敛** 等收敛速度.
        - 从 R-收敛速度的定义可以看出序列 $\{||x^{k}-x^{*}||\}$ 被另一趋于 0 的序列 $\{t_{k}\}$ 控制.
        - 当知道 $t_{k}$ 的形式时，我们也称算法（点列）的收敛速度为 $\mathcal{O}(t_{k})$.


9. **复杂度**
    - 与收敛速度密切相关的概念是优化算法的 **复杂度** $N(\varepsilon)$
        - 即计算出给定精度 $\varepsilon$ 的解所需的迭代次数或浮点运算次数.
    - 在实际应用中，这两种定义复杂度的方式均很常见.
    - 如果能较准确地估计每次迭代的运算量，则可以由算法所需迭代次数推出所需浮点运算次数.
    - 我们用具体的例子来进一步解释算法复杂度：  
        设某一算法产生的迭代序列 $\{x^{k}\}$ 满足:
        $$
        f(x^{k})-f(x^{*})\le \frac{c}{\sqrt{k}}, \space \forall k>0,
        $$
        - 其中 $c>0$ 为常数，$x^*$ 为全局极小点.
        - 如果需要计算算法满足精度 $f(x^{k})-f(x^*)\le \varepsilon$ 所需的迭代次数:
            - 只需令 $\frac{c}{\sqrt{k}}\le \varepsilon$
            - 则得到 $k\ge \frac{c^{2}}{\varepsilon ^{2}}$
            - 因此该优化算法对应的（迭代次数）复杂度为 $N(\varepsilon)=O(\frac{1}{\varepsilon ^{2}})$.
    - 注意：
        - 渐进收敛速度更多的是考虑迭代次数充分大的情形.
        - 而复杂度给出了算法迭代有限步之后产生的解与最优解之间的定量关系.



---



## 第二章 基础知识

### 考察内容
- 梯度海瑟矩阵 `28-29页`
- 凸集仿射集 `36页`
- 半正定矩阵 `39页`
- 凸函数： `42页`
    - 例题 2.5  `45页`
- 次梯度次微分： `51页`
    - 例题 2.10 — 2.12 `55页`

###  2.1 范数
### 2.2 导数
### 2.3 广义实值函数
### 2.4 凸集
### 2.5 凸函数
### 2.6 共轭函数
### 2.7 次梯度



---



## 第三章 典型优化问题

### 考察内容
- 线性规划： `62-63页`
    - 习题 3.1 3.2 `78页`
- 半定规划： `70—72页`
    - 习题 3.9 79页

### 3.1 线性规划
### 3.2 最小二乘问题
### 3.3 复合优化问题
### 3.4 随机优化问题
### 3.5 半定规划
### 3.6 矩阵优化
### 3.7 优化模型语言


---



## 第四章最优性理论

### 考察内容
- 下降方向： `85页`
    - 线性化可行方向
    - LICQ
    - Slater条件等
- 无约束可微问题的一阶必要条件，二阶最优性条件： `85—87页 `
    - 例题  `87页`
    - 习题 4.5 `115页`
- 无约束不可微问题的最优性理论： `89——91页`
- 对偶理论 例题 `96-100页`
    - 习题 4.7 `115页`
    - 习题 4.13 `116页 ` 
- 一般约束优化问题的最优性理论：
    - 例题 `107页`
    - 习题 4.10 `116页`
- 凸优化问题最优性理论：
    - 例题 `111页`
    - 习题 4.11(a)，4.6(b) `116页`


### 4.1 最优化问题解的存在性
### 4.2 无约束可微问题的最优性理论
### 4.3 无约束不可微问题的最优性理论
### 4.4 对偶理论
### 4.5 一般约束优化问题的最优性理论
### 4.6 带约束凸优化问题的最优性理论
### 4.7 约束优化最优性理论应用实例


---



## 第五章 无约束优化算法

### 考察内容
- 线搜索准则：
    - Armijo 准则 `121页`
    - Wolfe 准则 `123页`
- 梯度法迭代计算 `128页`
    - 定理 5.2
    - 习题 5.2 `179页`
- 步长：
    - 精确线性搜索；
    - BB 梯度法
    - BB 梯度法的两种迭代格式推理 `132页`
- 牛顿类算法：
    - 牛顿方程 牛顿方向 经典牛顿法迭代格式 `141页`
- 牛顿法的具体迭代计算：
    - 搜索方向 ：
        - 步长：1（即经典牛顿法）
        - 精确线性搜索
- 拟牛顿类算法：
    - 割线方程 `148页`
    - 拟牛顿矩阵更新公式推理；
        - SR1公式 5.5.9 `150页`
        - BFGS公式推理5.5.12 `151页`

### 5.1 线搜索方法
### 5.2 梯度类算法
### 5.3 次梯度算法
### 5.4 牛顿类算法
### 5.5 拟牛顿类算法
### 5.6 信赖域算法
### 5.7 非线性最小二乘问题算法
### 5.8 总结


---



## 第六章约束优化算法

### 考察内容
- 罚函数法：
    - 二次罚函数法
    - 对数罚函数法
- 等式约束优化问题
    - 增广拉格朗日函数法 


### 6.1 罚函数法
### 6.2 增广拉格朗日函数法




